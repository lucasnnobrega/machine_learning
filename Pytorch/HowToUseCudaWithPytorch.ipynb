{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf75c21-6fce-4d3c-8238-222e186b0970",
   "metadata": {},
   "source": [
    "[Link From Reference](https://wandb.ai/wandb/common-ml-errors/reports/How-To-Use-GPU-with-PyTorch---VmlldzozMzAxMDk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da84c9f-69b2-4cd6-ab2e-d9bdbdea08dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3501ed4e-1a5d-41ea-af47-376b3e71093b",
   "metadata": {},
   "source": [
    "# Use GPU - Gotchas\n",
    "By default, the tensors are generated on the CPU. Even the model is initialized on the CPU. Thus one has to manually ensure that the operations are done using GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df88f103-b6c6-47a6-849e-daa59a54ce1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.FloatTensor([0.0,1.0, 2.0])\n",
    "X_train.is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e76bd-1224-464f-b7aa-bf277209fab8",
   "metadata": {},
   "source": [
    "PyTorch provides a simple to use API to transfer the tensor generated on CPU to GPU. Luckily the new tensors are generated on the same device as the parent tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1044f1ce-a33b-4fde-a557-9d32f5bf04e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.to(\"cuda\")\n",
    "X_train.is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b12a2e2-98f8-4aa0-b60a-3f3f33bac640",
   "metadata": {},
   "source": [
    "The same logic applies to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b351e4-e9cd-41f7-8253-c38eabd7c62d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MyModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bafe7413dc5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MyModel' is not defined"
     ]
    }
   ],
   "source": [
    "model = MyModel(args)\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c81c8-98fc-4efa-9aec-547c0b555acb",
   "metadata": {},
   "source": [
    "Thus data and the model need to be transferred to the GPU. Well, what's device?\n",
    "It's a common PyTorch practice to initialize a variable, usually named device that will hold the device weâ€™re training on (CPU or GPU). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b91b6f85-ce89-487e-962f-4c3f81e38a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e51b0-e503-422b-a396-c29019a77585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e905d1df-6b6b-46ce-b791-ce9ef5f02f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
